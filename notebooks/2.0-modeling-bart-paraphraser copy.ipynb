{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.981983</td>\n",
       "      <td>0.014195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.999039</td>\n",
       "      <td>0.065473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.994215</td>\n",
       "      <td>0.053362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>0.009402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm not gonna have a child... ...with the same...</td>\n",
       "      <td>I'm not going to breed kids with a genetic dis...</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             3           3   \n",
       "3             4           4   \n",
       "4             5           5   \n",
       "\n",
       "                                           reference  \\\n",
       "0  if Alkar floods her with her mental waste, it ...   \n",
       "1                        you're becoming disgusting.   \n",
       "2                       monkey, you have to wake up.   \n",
       "3                         I have orders to kill her.   \n",
       "4  I'm not gonna have a child... ...with the same...   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...    0.785171     0.010309   \n",
       "1                          Now you're getting nasty.    0.749687     0.071429   \n",
       "2          Ah! Monkey, you've got to snap out of it.    0.664333     0.309524   \n",
       "3                   I've got orders to put her down.    0.726639     0.181818   \n",
       "4  I'm not going to breed kids with a genetic dis...    0.703185     0.206522   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.981983  0.014195  \n",
       "1  0.999039  0.065473  \n",
       "2  0.994215  0.053362  \n",
       "3  0.999348  0.009402  \n",
       "4  0.950956  0.035846  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\Productivity\\Studying\\PMLDL_A1\\data\\interim\\preprocessed.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123423</th>\n",
       "      <td>176381</td>\n",
       "      <td>176381</td>\n",
       "      <td>if he sees me, and I'm gonna look like that no...</td>\n",
       "      <td>If they get one look at me looking like this, ...</td>\n",
       "      <td>0.630866</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.980718</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320784</th>\n",
       "      <td>458500</td>\n",
       "      <td>458500</td>\n",
       "      <td>you fuck me because once you have a problem, y...</td>\n",
       "      <td>I'm pissed off because every time you have a p...</td>\n",
       "      <td>0.723548</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.018898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84650</th>\n",
       "      <td>120912</td>\n",
       "      <td>120912</td>\n",
       "      <td>Sergeant, why are you breaking my balls here?</td>\n",
       "      <td>sergeant, why do you keep bumping into me?</td>\n",
       "      <td>0.661492</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.997737</td>\n",
       "      <td>0.000903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106439</th>\n",
       "      <td>152110</td>\n",
       "      <td>152110</td>\n",
       "      <td>that's the stupidest idea I've ever heard.</td>\n",
       "      <td>That is the worst idea I've ever heard.</td>\n",
       "      <td>0.858453</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389618</th>\n",
       "      <td>556394</td>\n",
       "      <td>556394</td>\n",
       "      <td>trust me, pussycat.</td>\n",
       "      <td>Trust me, kitty Kat.</td>\n",
       "      <td>0.877873</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.993290</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297474</th>\n",
       "      <td>425367</td>\n",
       "      <td>425367</td>\n",
       "      <td>you want to show me what the damn basics are?</td>\n",
       "      <td>You want to show me, uh, what the heck a footi...</td>\n",
       "      <td>0.785450</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.996686</td>\n",
       "      <td>0.008486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209753</th>\n",
       "      <td>299428</td>\n",
       "      <td>299428</td>\n",
       "      <td>Bury them now, missy?</td>\n",
       "      <td>bury them now?</td>\n",
       "      <td>0.836797</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.949059</td>\n",
       "      <td>0.001496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104067</th>\n",
       "      <td>148697</td>\n",
       "      <td>148697</td>\n",
       "      <td>Open the door and throw that bitch out.</td>\n",
       "      <td>open the door and throw it out.</td>\n",
       "      <td>0.835778</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.021942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39667</th>\n",
       "      <td>56732</td>\n",
       "      <td>56732</td>\n",
       "      <td>I don't know how you're going with your father...</td>\n",
       "      <td>I don't know about you and your father but let...</td>\n",
       "      <td>0.790343</td>\n",
       "      <td>0.043796</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.025873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32035</th>\n",
       "      <td>45854</td>\n",
       "      <td>45854</td>\n",
       "      <td>Fisher, your mom's a milf!</td>\n",
       "      <td>Fisher, your mom is MBRO!</td>\n",
       "      <td>0.799395</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323660 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1  Unnamed: 0  \\\n",
       "123423        176381      176381   \n",
       "320784        458500      458500   \n",
       "84650         120912      120912   \n",
       "106439        152110      152110   \n",
       "389618        556394      556394   \n",
       "...              ...         ...   \n",
       "297474        425367      425367   \n",
       "209753        299428      299428   \n",
       "104067        148697      148697   \n",
       "39667          56732       56732   \n",
       "32035          45854       45854   \n",
       "\n",
       "                                                reference  \\\n",
       "123423  if he sees me, and I'm gonna look like that no...   \n",
       "320784  you fuck me because once you have a problem, y...   \n",
       "84650       Sergeant, why are you breaking my balls here?   \n",
       "106439         that's the stupidest idea I've ever heard.   \n",
       "389618                                trust me, pussycat.   \n",
       "...                                                   ...   \n",
       "297474      you want to show me what the damn basics are?   \n",
       "209753                              Bury them now, missy?   \n",
       "104067            Open the door and throw that bitch out.   \n",
       "39667   I don't know how you're going with your father...   \n",
       "32035                          Fisher, your mom's a milf!   \n",
       "\n",
       "                                              translation  similarity  \\\n",
       "123423  If they get one look at me looking like this, ...    0.630866   \n",
       "320784  I'm pissed off because every time you have a p...    0.723548   \n",
       "84650          sergeant, why do you keep bumping into me?    0.661492   \n",
       "106439            That is the worst idea I've ever heard.    0.858453   \n",
       "389618                               Trust me, kitty Kat.    0.877873   \n",
       "...                                                   ...         ...   \n",
       "297474  You want to show me, uh, what the heck a footi...    0.785450   \n",
       "209753                                     bury them now?    0.836797   \n",
       "104067                    open the door and throw it out.    0.835778   \n",
       "39667   I don't know about you and your father but let...    0.790343   \n",
       "32035                           Fisher, your mom is MBRO!    0.799395   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "123423     0.058824  0.980718  0.000230  \n",
       "320784     0.142857  0.999320  0.018898  \n",
       "84650      0.065217  0.997737  0.000903  \n",
       "106439     0.069767  0.999686  0.015469  \n",
       "389618     0.047619  0.993290  0.000194  \n",
       "...             ...       ...       ...  \n",
       "297474     0.132075  0.996686  0.008486  \n",
       "209753     0.318182  0.949059  0.001496  \n",
       "104067     0.200000  0.999542  0.021942  \n",
       "39667      0.043796  0.999340  0.025873  \n",
       "32035      0.037037  0.957364  0.001938  \n",
       "\n",
       "[323660 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=0.8, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159775</th>\n",
       "      <td>he doesn't like geeks.</td>\n",
       "      <td>He does not like Geisha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211169</th>\n",
       "      <td>and try pointing and shooting at them, not int...</td>\n",
       "      <td>And try to aim and hit them, not me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377322</th>\n",
       "      <td>and I want you to have one deep inside of you.</td>\n",
       "      <td>But I want you to have one in depth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12014</th>\n",
       "      <td>Betting's for suckers.</td>\n",
       "      <td>betting is for magicians.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107946</th>\n",
       "      <td>I killed him a week ago.</td>\n",
       "      <td>Just last week I had a slip.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input_text  \\\n",
       "159775                             he doesn't like geeks.   \n",
       "211169  and try pointing and shooting at them, not int...   \n",
       "377322     and I want you to have one deep inside of you.   \n",
       "12014                              Betting's for suckers.   \n",
       "107946                           I killed him a week ago.   \n",
       "\n",
       "                                 target_text  \n",
       "159775              He does not like Geisha.  \n",
       "211169  And try to aim and hit them, not me.  \n",
       "377322  But I want you to have one in depth.  \n",
       "12014              betting is for magicians.  \n",
       "107946          Just last week I had a slip.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\"reference\": \"input_text\", \"translation\": \"target_text\"})\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train = pd.DataFrame(train, columns = ['input_text','target_text'])\n",
    "test = pd.DataFrame(test, columns = ['input_text','target_text'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97444</th>\n",
       "      <td>Semantics. You say tomato-- No, motherfucker, ...</td>\n",
       "      <td>you say tomato No, I didn't say \"tomato.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235611</th>\n",
       "      <td>We forgot the word processor, but we left you ...</td>\n",
       "      <td>we've forgotten the text processor, but we lef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134721</th>\n",
       "      <td>You idiot! You gonna spill hot coffee all over...</td>\n",
       "      <td>he's covered me with a hot coffee, huh?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183956</th>\n",
       "      <td>No, you do... you do that and then that's what...</td>\n",
       "      <td>no, you do this. That's what men do when they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28775</th>\n",
       "      <td>he can have a baby with you if you don't even ...</td>\n",
       "      <td>How can she have a child by you, when you won'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input_text  \\\n",
       "97444   Semantics. You say tomato-- No, motherfucker, ...   \n",
       "235611  We forgot the word processor, but we left you ...   \n",
       "134721  You idiot! You gonna spill hot coffee all over...   \n",
       "183956  No, you do... you do that and then that's what...   \n",
       "28775   he can have a baby with you if you don't even ...   \n",
       "\n",
       "                                              target_text  \n",
       "97444           you say tomato No, I didn't say \"tomato.\"  \n",
       "235611  we've forgotten the text processor, but we lef...  \n",
       "134721            he's covered me with a hot coffee, huh?  \n",
       "183956  no, you do this. That's what men do when they ...  \n",
       "28775   How can she have a child by you, when you won'...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = Seq2SeqArgs()\n",
    "model_args.eval_batch_size = 64\n",
    "model_args.evaluate_generated_text = True\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.evaluate_during_training_steps = 2500\n",
    "model_args.evaluate_during_training_verbose = True\n",
    "model_args.fp16 = False\n",
    "model_args.learning_rate = 5e-5\n",
    "model_args.max_seq_length = 128\n",
    "model_args.num_train_epochs = 2\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.save_steps = -1\n",
    "model_args.train_batch_size = 8\n",
    "model_args.use_multiprocessing = False\n",
    "\n",
    "model_args.do_sample = True\n",
    "model_args.num_beams = 1\n",
    "model_args.num_return_sequences = 1\n",
    "model_args.max_length = 128\n",
    "model_args.top_k = 50\n",
    "model_args.top_p = 0.95\n",
    "model_args.output_dir = \"./models/tany\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Productivity\\Studying\\PMLDL_A1\\notebooks\\2.0-modeling-bart-paraphraser copy.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Productivity/Studying/PMLDL_A1/notebooks/2.0-modeling-bart-paraphraser%20copy.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Seq2SeqModel(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Productivity/Studying/PMLDL_A1/notebooks/2.0-modeling-bart-paraphraser%20copy.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     encoder_decoder_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbart\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Productivity/Studying/PMLDL_A1/notebooks/2.0-modeling-bart-paraphraser%20copy.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     encoder_decoder_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39meugenesiow/bart-paraphrase\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Productivity/Studying/PMLDL_A1/notebooks/2.0-modeling-bart-paraphraser%20copy.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     args\u001b[39m=\u001b[39;49mmodel_args,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Productivity/Studying/PMLDL_A1/notebooks/2.0-modeling-bart-paraphraser%20copy.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     use_cuda\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Productivity/Studying/PMLDL_A1/notebooks/2.0-modeling-bart-paraphraser%20copy.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     use_mps_device \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Productivity/Studying/PMLDL_A1/notebooks/2.0-modeling-bart-paraphraser%20copy.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Productivity/Studying/PMLDL_A1/notebooks/2.0-modeling-bart-paraphraser%20copy.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mtrain_model(train, eval_data\u001b[39m=\u001b[39mtest)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\simpletransformers\\seq2seq\\seq2seq_model.py:314\u001b[0m, in \u001b[0;36mSeq2SeqModel.__init__\u001b[1;34m(self, encoder_type, encoder_name, decoder_name, encoder_decoder_type, encoder_decoder_name, additional_special_tokens_encoder, additional_special_tokens_decoder, index_name, knowledge_dataset, index_path, dpr_ctx_encoder_model_name, rag_question_encoder_model_name, config, args, use_cuda, cuda_device, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m     config_class, model_class, tokenizer_class \u001b[39m=\u001b[39m MODEL_CLASSES[encoder_type]\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m encoder_decoder_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbart\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmbart\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmbart50\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmarian\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(encoder_decoder_name)\n\u001b[0;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m encoder_decoder_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbart\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmbart\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmbart50\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    316\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_tokenizer \u001b[39m=\u001b[39m tokenizer_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    317\u001b[0m             encoder_decoder_name\n\u001b[0;32m    318\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\modeling_utils.py:3085\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3082\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_check_and_enable_flash_attn_2(config, torch_dtype\u001b[39m=\u001b[39mtorch_dtype, device_map\u001b[39m=\u001b[39mdevice_map)\n\u001b[0;32m   3084\u001b[0m \u001b[39mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-> 3085\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(config, \u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[0;32m   3087\u001b[0m \u001b[39m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[0;32m   3088\u001b[0m \u001b[39mif\u001b[39;00m use_keep_in_fp32_modules:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1314\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config: BartConfig):\n\u001b[0;32m   1313\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m BartModel(config)\n\u001b[0;32m   1315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_buffer(\u001b[39m\"\u001b[39m\u001b[39mfinal_logits_bias\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared\u001b[39m.\u001b[39mnum_embeddings)))\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(config\u001b[39m.\u001b[39md_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared\u001b[39m.\u001b[39mnum_embeddings, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1189\u001b[0m, in \u001b[0;36mBartModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1186\u001b[0m padding_idx, vocab_size \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpad_token_id, config\u001b[39m.\u001b[39mvocab_size\n\u001b[0;32m   1187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(vocab_size, config\u001b[39m.\u001b[39md_model, padding_idx)\n\u001b[1;32m-> 1189\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m BartEncoder(config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshared)\n\u001b[0;32m   1190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m BartDecoder(config, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared)\n\u001b[0;32m   1192\u001b[0m \u001b[39m# Initialize weights and apply final processing\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bart\\modeling_bart.py:741\u001b[0m, in \u001b[0;36mBartEncoder.__init__\u001b[1;34m(self, config, embed_tokens)\u001b[0m\n\u001b[0;32m    735\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m embed_tokens\u001b[39m.\u001b[39mweight\n\u001b[0;32m    737\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_positions \u001b[39m=\u001b[39m BartLearnedPositionalEmbedding(\n\u001b[0;32m    738\u001b[0m     config\u001b[39m.\u001b[39mmax_position_embeddings,\n\u001b[0;32m    739\u001b[0m     embed_dim,\n\u001b[0;32m    740\u001b[0m )\n\u001b[1;32m--> 741\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([BartEncoderLayer(config) \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(config\u001b[39m.\u001b[39;49mencoder_layers)])\n\u001b[0;32m    742\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm_embedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(embed_dim)\n\u001b[0;32m    744\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_checkpointing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bart\\modeling_bart.py:741\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    735\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m embed_tokens\u001b[39m.\u001b[39mweight\n\u001b[0;32m    737\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_positions \u001b[39m=\u001b[39m BartLearnedPositionalEmbedding(\n\u001b[0;32m    738\u001b[0m     config\u001b[39m.\u001b[39mmax_position_embeddings,\n\u001b[0;32m    739\u001b[0m     embed_dim,\n\u001b[0;32m    740\u001b[0m )\n\u001b[1;32m--> 741\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([BartEncoderLayer(config) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config\u001b[39m.\u001b[39mencoder_layers)])\n\u001b[0;32m    742\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm_embedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(embed_dim)\n\u001b[0;32m    744\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_checkpointing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bart\\modeling_bart.py:310\u001b[0m, in \u001b[0;36mBartEncoderLayer.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_dropout \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mactivation_dropout\n\u001b[0;32m    309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, config\u001b[39m.\u001b[39mencoder_ffn_dim)\n\u001b[1;32m--> 310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mLinear(config\u001b[39m.\u001b[39;49mencoder_ffn_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim)\n\u001b[0;32m    311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_layer_norm \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:101\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_parameter(\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_parameters()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:107\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset_parameters\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     \u001b[39m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[39m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[39m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m     init\u001b[39m.\u001b[39;49mkaiming_uniform_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, a\u001b[39m=\u001b[39;49mmath\u001b[39m.\u001b[39;49msqrt(\u001b[39m5\u001b[39;49m))\n\u001b[0;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m         fan_in, _ \u001b[39m=\u001b[39m init\u001b[39m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\init.py:419\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[1;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[0;32m    417\u001b[0m bound \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39m3.0\u001b[39m) \u001b[39m*\u001b[39m std  \u001b[39m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 419\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49muniform_(\u001b[39m-\u001b[39;49mbound, bound)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Seq2SeqModel(\n",
    "    encoder_decoder_type=\"bart\",\n",
    "    encoder_decoder_name=\"eugenesiow/bart-paraphrase\",\n",
    "    args=model_args,\n",
    "    use_cuda=False,\n",
    "    use_mps_device = True\n",
    ")\n",
    "model.train_model(train, eval_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753b9a6c423a4e94a8e4663970803716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/strangetany/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "/Users/strangetany/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test[\"input_text\"][:5].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I want to believe Okwe never fucked you.',\n",
       " \"Why didn't the mountain provide a pass for sledging.\",\n",
       " \"Loyalty to anybody: I'm Glad you're back in town, Mr. Clinton. Yeah, me too.\",\n",
       " \"He's ashamed of you because you have a blob in your life.\",\n",
       " 'If I had a rape whistle, would you call me a feminist, what should I do?']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93               I can't believe Okwe never fucked you.\n",
       "57                  I don't need a mountain for chumps.\n",
       "91    Damn, I'm glad you're back in town. Yeah, me too.\n",
       "39    he's ashamed of you because you have a blob in...\n",
       "88            We're gonna send you a rape whistle. Huh?\n",
       "Name: input_text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"input_text\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
